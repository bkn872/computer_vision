{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bkn872/computer_vision/blob/main/Resubmit__Computer_vision_Project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inkTv-TtvoBm"
      },
      "source": [
        "Computer Vision Module Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnMcpexJ1Kws"
      },
      "source": [
        "# ***Part A - 30 Marks*** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZCLgWu2Bvx2I"
      },
      "source": [
        "**• DOMAIN:** Botanical Research\n",
        "\n",
        "**• CONTEXT:** University X is currently undergoing some research involving understanding the characteristics of plant and plant seedlings at\n",
        "various stages of growth. They already have have invested on curating sample images. They require an automation which can create a\n",
        "classifier capable of determining a plant's species from a photo.\n",
        "\n",
        "**• DATA DESCRIPTION:** The dataset comprises of images from 12 plant species.\n",
        "Source: https://www.kaggle.com/c/plant-seedlings-classification/data.\n",
        "\n",
        "**• PROJECT OBJECTIVE:** To create a classifier capable of determining a plant's species from a photo\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f2UYh94dMWTJ"
      },
      "source": [
        "# **1.1. Import and Understand the data [12 Marks]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7qZR4qu-MfZ8"
      },
      "source": [
        "### 1.1.A. Extract ‘plant-seedlings-classification.zip’ into new folder (unzipped) using python. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np # MATRIX OPERATIONS\n",
        "import pandas as pd # EFFICIENT DATA STRUCTURES\n",
        "import matplotlib.pyplot as plt # GRAPHING AND VISUALIZATIONS\n",
        "import math # MATHEMATICAL OPERATIONS\n",
        "import cv2 # IMAGE PROCESSING - OPENCV\n",
        "from glob import glob # FILE OPERATIONS\n",
        "import itertools\n",
        "# KERAS AND SKLEARN MODULES\n",
        "from keras.utils import np_utils\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import Flatten\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from keras.layers.convolutional import MaxPooling2D\n",
        "from keras.layers import BatchNormalization\n",
        "from keras.callbacks import ModelCheckpoint,ReduceLROnPlateau,CSVLogger\n",
        "from sklearn import preprocessing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix\n",
        "# GLOBAL VARIABLES\n",
        "scale = 70\n",
        "seed = 7"
      ],
      "metadata": {
        "id": "OE2KrbO027hh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "path_to_images = \"/content/drive/MyDrive/Python/CV/plant_seedlings_classification.zip\"\n",
        "\n",
        "\n",
        "#path_to_images = 'plant-seedlings-classification/train/png'\n",
        "images = glob(path_to_images)\n",
        "trainingset = []\n",
        "traininglabels = []\n",
        "num = len(images)\n",
        "count = 1\n",
        "#READING IMAGES AND RESIZING THEM\n",
        "for i in images:\n",
        "    print(str(count)+'/'+str(num),end='r')\n",
        "    trainingset.append(cv2.resize(cv2.imread(i),(scale,scale)))\n",
        "    traininglabels.append(i.split('/')[-2])\n",
        "    count=count+1\n",
        "trainingset = np.asarray(trainingset)\n",
        "traininglabels = pd.DataFrame(traininglabels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 301
        },
        "id": "r5u2Roz53OQV",
        "outputId": "daf90df4-5b2d-48ac-ed63-9c545ca0f65e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Mounted at /content/drive\n",
            "1/1r"
          ]
        },
        {
          "output_type": "error",
          "ename": "error",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-772d15e790ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mtrainingset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mtraininglabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31merror\u001b[0m: OpenCV(4.6.0) /io/opencv/modules/imgproc/src/resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'resize'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "new_train = []\n",
        "sets = []; getEx = True\n",
        "for i in trainingset:\n",
        "    blurr = cv2.GaussianBlur(i,(5,5),0)\n",
        "    hsv = cv2.cvtColor(blurr,cv2.COLOR_BGR2HSV)\n",
        "    #GREEN PARAMETERS\n",
        "    lower = (25,40,50)\n",
        "    upper = (75,255,255)\n",
        "    mask = cv2.inRange(hsv,lower,upper)\n",
        "    struc = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(11,11))\n",
        "    mask = cv2.morphologyEx(mask,cv2.MORPH_CLOSE,struc)\n",
        "    boolean = mask>0\n",
        "    new = np.zeros_like(i,np.uint8)\n",
        "    new[boolean] = i[boolean]\n",
        "    new_train.append(new)\n",
        "    if getEx:\n",
        "        plt.subplot(2,3,1);plt.imshow(i) # ORIGINAL\n",
        "        plt.subplot(2,3,2);plt.imshow(blurr) # BLURRED\n",
        "        plt.subplot(2,3,3);plt.imshow(hsv) # HSV CONVERTED\n",
        "        plt.subplot(2,3,4);plt.imshow(mask) # MASKED\n",
        "        plt.subplot(2,3,5);plt.imshow(boolean) # BOOLEAN MASKED\n",
        "        plt.subplot(2,3,6);plt.imshow(new) # NEW PROCESSED IMAGE\n",
        "        plt.show()\n",
        "        getEx = False\n",
        "new_train = np.asarray(new_train)\n",
        "# CLEANED IMAGES\n",
        "for i in range(8):\n",
        "    plt.subplot(2,4,i+1)\n",
        "    plt.imshow(new_train[i])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 343
        },
        "id": "7Kl8msCx3hVR",
        "outputId": "6b34630f-b249-4ee1-c36f-160202f7618c"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-0e6fbe293ee7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xVU6K6G5CoRJ",
        "outputId": "d0553277-e5a2-4152-bf41-34de6769c13b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        }
      ],
      "source": [
        "%tensorflow_version 2.x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5PuOX8xUtmqI"
      },
      "outputs": [],
      "source": [
        "import zipfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "47V1eBjswbhW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecee110d-1bdf-44bf-85a5-bef168d2579a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "TODMt0GFLi5o"
      },
      "outputs": [],
      "source": [
        "images_path = \"/content/drive/MyDrive/Python/CV/plant_seedlings_classification.zip\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J63BIKQMotP8"
      },
      "source": [
        "#Extract Zip File"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "lwpI29KiDcbi"
      },
      "outputs": [],
      "source": [
        "from zipfile import ZipFile\n",
        "with ZipFile(images_path,'r') as zip:\n",
        "  zip.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuDScr3iiNox",
        "outputId": "7f0e17ff-1b15-4c8d-d4cc-ad4b1f531133"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  __MACOSX  plant-seedlings-classification  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#to know the all files in the zip \n",
        "#zip.printdir()"
      ],
      "metadata": {
        "id": "36J0JHQ_4zy7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "nZMGx_8iDq4_"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dense, Dropout\n",
        "from tensorflow.keras.optimizers import Adam"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image\n",
        "#import skimage.io as io\n",
        "#import matplotlib.pyplot as plt\n",
        "#img = io.imread(\"/content/drive/MyDrive/Python/CV/pflower.jpg\")\n",
        "\n",
        "\n",
        "#plt.imshow(img)\n",
        "#plt.show()"
      ],
      "metadata": {
        "id": "7BCpDxs9dKIZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XeYscBQINGzY"
      },
      "source": [
        "### 1.1.B. Map the images from train folder with train labels to form a DataFrame. [6 Marks]\n",
        "\n",
        "Hint: Create a DataFrame with 3 columns: Name of image, Species/class/type of image & actual image.."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qg0yjrycEILg"
      },
      "outputs": [],
      "source": [
        "# Initialising the CNN classifier\n",
        "classifier = Sequential()\n",
        "\n",
        "# Add a Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Add a Max Pooling layer of size 2X2\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Add another Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Adding another pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Add another Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Adding another pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Flattening the layer before fully connected layers\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Adding a fully connected layer with 512 neurons\n",
        "classifier.add(Dense(units = 512, activation = 'relu'))\n",
        "\n",
        "# Adding dropout with probability 0.5\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# Adding a fully connected layer with 128 neurons\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "\n",
        "# The final output layer with 5 neuron to predict the categorical classifcation\n",
        "classifier.add(Dense(units = 5, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w04e5yac_4IO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b177d6f-b505-4429-db05-c7d9c72ede97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/keras/optimizers/optimizer_v2/adam.py:110: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  super(Adam, self).__init__(name, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
        "classifier.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Create data generator for training data with data augmentation and normalizing all\n",
        "# values by 255\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Setting training data generator's source directory\n",
        "# Setting the target size to resize all the images to (64,64) as the model input layer expects 32X32 images\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('./plant_seedlings_classification/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n",
        "# Setting testing data generator's source directory\n",
        "test_set = test_datagen.flow_from_directory('./plant_seedlings_classification/test',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "\n",
        "# There are 3823 training images and 500 test images in total\n",
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch = int(3823/32),\n",
        "                         epochs = 20,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = int(500/32))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "1lfioH_-mMAG",
        "outputId": "b4ac4fc4-b194-43b7-cf78-463589b1c801"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-07dbe33cd20a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Setting the target size to resize all the images to (64,64) as the model input layer expects 32X32 images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m training_set = train_datagen.flow_from_directory('./plant_seedlings_classification/train',\n\u001b[0m\u001b[1;32m     18\u001b[0m                                                  \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1467\u001b[0m             \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m     \"\"\"\n\u001b[0;32m-> 1469\u001b[0;31m     return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1470\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m       \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m           \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './plant_seedlings_classification/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KNN69kVcAcqL"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "\n",
        "# Create data generator for training data with data augmentation and normalizing all\n",
        "# values by 255\n",
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "\n",
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "\n",
        "# Setting training data generator's source directory\n",
        "# Setting the target size to resize all the images to (64,64) as the model input layer expects 32X32 images\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(r\"/content/drive/My Drive\")\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('./plant_seedlings_classification/train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'categorical')\n",
        "\n"
      ],
      "metadata": {
        "id": "ej7PWTOcobeM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "outputId": "12203243-d17c-47dc-d7af-5f185e43f86c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-68202e1e2a5a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr\"/content/drive/My Drive\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m training_set = train_datagen.flow_from_directory('./plant_seedlings_classification/train',\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                  \u001b[0mtarget_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                  \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36mflow_from_directory\u001b[0;34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[0m\n\u001b[1;32m   1467\u001b[0m             \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0my\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mcorresponding\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1468\u001b[0m     \"\"\"\n\u001b[0;32m-> 1469\u001b[0;31m     return DirectoryIterator(\n\u001b[0m\u001b[1;32m   1470\u001b[0m         \u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/preprocessing/image.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m       \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m       \u001b[0;32mfor\u001b[0m \u001b[0msubdir\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdirectory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m           \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './plant_seedlings_classification/train'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Setting testing data generator's source directory\n",
        "test_set = test_datagen.flow_from_directory('./plant_seedlings_classification/',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "\n",
        "# There are 3823 training images and 500 test images in total\n",
        "classifier.fit_generator(training_set,\n",
        "                         steps_per_epoch = int(3823/32),\n",
        "                         epochs = 20,\n",
        "                         validation_data = test_set,\n",
        "                         validation_steps = int(500/32))"
      ],
      "metadata": {
        "id": "5gVEJymFk42l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Vbao8vhpM0LL"
      },
      "outputs": [],
      "source": [
        "classifier.save('./classifier.h5')\n",
        "\n",
        "classifier.save_weights('./classifier_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hq-m-UlPM77h"
      },
      "outputs": [],
      "source": [
        "!ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpjMm8_tNHQv"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing import image\n",
        "\n",
        "# Load the pre trained model from the HDF5 file saved previously\n",
        "pretrained_model = load_model('./classifier.h5')\n",
        "pretrained_model.load_weights('./classifier_weights.h5')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IEGD0ZSVOGnF"
      },
      "outputs": [],
      "source": [
        "# Re-initalizing the test data generator with shuffle=False to create the confusion matrix\n",
        "test_set = test_datagen.flow_from_directory('./plant-seedlings-classification',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            shuffle=False,\n",
        "                                            class_mode = 'categorical')\n",
        "\n",
        "# Predict the whole generator to get predictions\n",
        "Y_pred = classifier.predict_generator(test_set, int(500/32+1))\n",
        "\n",
        "# Find out the predictions classes with maximum probability\n",
        "y_pred = np.argmax(Y_pred, axis=1)\n",
        "\n",
        "# Utilities for confusion matrix\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "\n",
        "# Printing the confusion matrix based on the actual data vs predicted data. \n",
        "print(confusion_matrix(test_set.classes, y_pred))\n",
        "\n",
        "# Printing the classification report\n",
        "print(classification_report(test_set.classes, y_pred, target_names=prediction_class))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0PbB7_o-i3uo"
      },
      "outputs": [],
      "source": [
        "\n",
        "import os"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kutlwWtbOpBT"
      },
      "source": [
        "### 1.1.C. Write a function that will select n random images and display images along with its species. [4 Marks]\n",
        "\n",
        "Hint: If input for function is 5, it should print 5 random images along with its labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7HcPDCXVQ_ij"
      },
      "outputs": [],
      "source": [
        "from zipFile import Zipfile \n",
        "with ZipFile('content/drive/MyDrive/Python/CV/plant-seedlings-classification.zip','r') as zipObj:\n",
        "zipObj.extractall ('content/drive/MyDrive/test')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z9rYCHRBPIH7"
      },
      "outputs": [],
      "source": [
        "print(type(images_path))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ACZZqy6zedpo"
      },
      "outputs": [],
      "source": [
        "img_rows=128\n",
        "img_cols=128\n",
        "num_channel=1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dei2YsqaWecF"
      },
      "source": [
        "# **2. Data preprocessing [8 Marks]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLXTW1wJWjTR"
      },
      "source": [
        "### A. Create X & Y from the DataFrame. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8YW4hItgWn9a"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fegxggmQWobS"
      },
      "source": [
        "### B. Encode labels of the images. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n8CIpkDGxfqS"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YzoamEicW5IS"
      },
      "source": [
        "### C. Unify shape of all the images. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JhxPwGFhW9xR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t0Y7KM9RW-qC"
      },
      "source": [
        "### D. Normalise all the images. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MRyRGcNOXGI6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8hfjzflXEKZ"
      },
      "source": [
        "### 3. Model training [10 Marks]\n",
        "\n",
        "### Checkpoint: Please make sure if shape of X is (No.of images, height, width, No. Of channels). If not, you need to correct it otherwise it will be issue during model training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ifoKDGH_XQNe"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEYPOO8VXg6q"
      },
      "source": [
        "### A. Split the data into train and test data. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "frDsMWw-XPSZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S9CDdInyXnxl"
      },
      "source": [
        "### B. Create new CNN architecture to train the model. [4 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgNWEl9EXwnh"
      },
      "outputs": [],
      "source": [
        "# Initialising the CNN classifier\n",
        "classifier = Sequential()\n",
        "\n",
        "# Add a Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), input_shape = (64, 64, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Add a Max Pooling layer of size 2X2\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Add another Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Adding another pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Add another Convolution layer with 32 kernels of 3X3 shape with activation function ReLU\n",
        "classifier.add(Conv2D(32, (3, 3), activation = 'relu', padding = 'same'))\n",
        "\n",
        "# Adding another pooling layer\n",
        "classifier.add(MaxPooling2D(pool_size = (2, 2)))\n",
        "\n",
        "# Flattening the layer before fully connected layers\n",
        "classifier.add(Flatten())\n",
        "\n",
        "# Adding a fully connected layer with 512 neurons\n",
        "classifier.add(Dense(units = 512, activation = 'relu'))\n",
        "\n",
        "# Adding dropout with probability 0.5\n",
        "classifier.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# Adding a fully connected layer with 128 neurons\n",
        "classifier.add(Dense(units = 128, activation = 'relu'))\n",
        "\n",
        "\n",
        "# The final output layer with 5 neuron to predict the categorical classifcation\n",
        "classifier.add(Dense(units = 5, activation = 'softmax'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Zm9VMFrxKgq"
      },
      "outputs": [],
      "source": [
        "opt = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.001, amsgrad=False)\n",
        "classifier.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbCMeb5YXqOq"
      },
      "source": [
        "### C. Train the model on train data and validate on test data. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-yAIH4StX4yZ"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ek_kET0TX3Ti"
      },
      "source": [
        "### D. Select a random image and print actual label and predicted label for the same. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2XVefne2X_G6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7B5nYSCPYEj6"
      },
      "source": [
        "# **Part B - 30 Marks**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HgtCW4-CYLuJ"
      },
      "source": [
        "**• DOMAIN:** Botanical Research\n",
        "\n",
        "**• CONTEXT:** University X is currently undergoing some research involving understanding the characteristics of flowers. They already have\n",
        "have invested on curating sample images. They require an automation which can create a classifier capable of determining a flower’s\n",
        "species from a photo.\n",
        "\n",
        "**• DATA DESCRIPTION:** The dataset comprises of images from 17 plant species.\n",
        "\n",
        "**• PROJECT OBJECTIVE:** To experiment with various approaches to train an image classifier to predict type of flower from the image."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wXcMvSpYc4a"
      },
      "source": [
        "## **Steps and tasks: [ Total Score: 30 Marks]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtvoR2Z_YjaR"
      },
      "source": [
        "# **1. Import and Understand the data [5 Marks]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UamfR15_YwzB"
      },
      "source": [
        "### A. Import and read oxflower17 dataset from tflearn and split into X and Y while loading. [2 Marks]\n",
        "\n",
        "Hint: It can be imported from tflearn.datasets. If tflearn is not installed, install it.\n",
        "\n",
        "It can be loaded using: x, y = oxflower17.load_data() "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GZpTelBrDp6D"
      },
      "outputs": [],
      "source": [
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip"
      ],
      "metadata": {
        "id": "HbBhwoILeOev"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow\n",
        "tensorflow.__version__"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "id": "95f9q45bxz7x",
        "outputId": "8f61a09f-30f9-4458-813f-982b127b9723"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'2.9.2'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!apt"
      ],
      "metadata": {
        "id": "3ef0hTmfebSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#conda install pip\n",
        "#!pip install tflearn"
      ],
      "metadata": {
        "id": "4GIqf1bNevzN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#import tflearn.datasets.oxflower17 as oxflower17"
      ],
      "metadata": {
        "id": "7maZZrKnd_DU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m--uE4mLxZQf",
        "outputId": "555ce024-ed6c-434b-cd97-a3e7297482de"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install tflearn "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "be6CjEks9QIk",
        "outputId": "f1699bd5-92b6-49a1-8ef0-694e5b89cc21"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tflearn\n",
            "  Downloading tflearn-0.5.0.tar.gz (107 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.3/107.3 KB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.21.6)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.8/dist-packages (from tflearn) (1.15.0)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.8/dist-packages (from tflearn) (7.1.2)\n",
            "Building wheels for collected packages: tflearn\n",
            "  Building wheel for tflearn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tflearn: filename=tflearn-0.5.0-py3-none-any.whl size=127299 sha256=6958daf6674c9a501ae825743fe230299f4e27560fb5c7342be4b9391b959678\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/9b/15/cb1e6b279c14ed897530d15cfd7da8e3df8a947e593f5cfe59\n",
            "Successfully built tflearn\n",
            "Installing collected packages: tflearn\n",
            "Successfully installed tflearn-0.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflearn"
      ],
      "metadata": {
        "id": "6H0O3gTu7Q_7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7545e1f-9477-4d2f-9339-dd5a303d67b9"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.8/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tflearn.datasets.oxflower17 as oxflower17 \n",
        "# X, Y = oxflower17.load_data(one_hot=True, resize_pics=(227, 227)) "
      ],
      "metadata": {
        "id": "RKvI1ENe8-Qc"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, Y = oxflower17.load_data(one_hot=True, resize_pics=(227, 227)) "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFY1kkM59XNr",
        "outputId": "82242407-6ed6-48d6-f651-c90c5f910026"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading Oxford 17 category Flower Dataset, Please wait...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100.0% 60276736 / 60270631\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Succesfully downloaded 17flowers.tgz 60270631 bytes.\n",
            "File Extracted\n",
            "Starting to parse images...\n",
            "Parsing Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from tensorflow.keras.datasets import mnist\n",
        "\n",
        "# the data, shuffled and split between train and test sets\n",
        "(X_train, y_train), (X_test, y_test) = oxflower17.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "QKLnMBG2yGH4",
        "outputId": "3c173131-b7d4-4368-d685-82a97f656a32"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-62d8df2f0da8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# the data, shuffled and split between train and test sets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moxflower17\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 2)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the random number generator\n",
        "import random\n",
        "random.seed(0)\n",
        "\n",
        "# Ignore the warnings\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "metadata": {
        "id": "4fEuyrdex7Ts"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read the image\n",
        "img = io.imread(\"/content/drive/MyDrive/Python/CV/pflower.jpg\")\n",
        "\n",
        "\n",
        "plt.imshow(img)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "xt810mgQxI2N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#pickle.load(open(dataset_file, 'rb'), encoding='latin1')"
      ],
      "metadata": {
        "id": "q4vXHYRB8IUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EP8H3EbgOaYw"
      },
      "outputs": [],
      "source": [
        "img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kw0HfOcCOioA"
      },
      "outputs": [],
      "source": [
        "# Split\n",
        "red = img[:, :, 0]\n",
        "green = img[:, :, 1]\n",
        "blue = img[:, :, 2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y53takNVOum_"
      },
      "outputs": [],
      "source": [
        "plt.imshow(red, cmap=\"Reds\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A1bl6wUXO6xr"
      },
      "outputs": [],
      "source": [
        "plt.imshow(green, cmap=\"Greens\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R-YgHe3yPAHD"
      },
      "outputs": [],
      "source": [
        "plt.imshow(blue, cmap=\"Blues\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0rxaTZ-DPaOH"
      },
      "outputs": [],
      "source": [
        "def filtering(img, f=3):\n",
        "    \n",
        "    # Dimensions from the input shape\n",
        "    (rows, col, channels) = img.shape\n",
        "    \n",
        "    # Initialize \"hyper parameters\"\n",
        "    stride = 2\n",
        "    \n",
        "    # Dimensions of the output\n",
        "    n_rows = int(1 + (rows - f) / stride)\n",
        "    n_col = int(1 + (col - f) / stride)\n",
        "    n_channels = channels\n",
        "    \n",
        "    # Initialize output matrix A\n",
        "    n_img = np.zeros((n_rows, n_col, n_channels))              \n",
        "    \n",
        "    # iterate through img\n",
        "    for h in range(n_rows):                     \n",
        "        for w in range(n_col):                 \n",
        "            for c in range (n_channels):            \n",
        "                vert_start = h*stride\n",
        "                vert_end = vert_start + f\n",
        "                horiz_start = w*stride\n",
        "                horiz_end = horiz_start + f\n",
        "\n",
        "                # extract slice we are dealing with\n",
        "                n_slice = img[vert_start:vert_end, horiz_start:horiz_end, c]\n",
        "\n",
        "                # Compute the filtering operation on the slice\n",
        "                n_img[h, w, c] = np.mean(n_slice, dtype=int)\n",
        "    return n_img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mANYBJujPlXs"
      },
      "outputs": [],
      "source": [
        "A = filtering(img)\n",
        "print(A.shape)\n",
        "plt.imshow(A)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "09oSdNXwPl5M"
      },
      "outputs": [],
      "source": [
        "A = filtering(img, f=11)\n",
        "print (A.shape)\n",
        "plt.imshow(A)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M5UXmFQtP5VW"
      },
      "outputs": [],
      "source": [
        "A = filtering(img, f=25)\n",
        "print(A.shape)\n",
        "plt.imshow(A)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5CHNDTcY04h"
      },
      "source": [
        "### B. Print Number of images and shape of the images. [1 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MCYSMzjOZEZ8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "11wofcIXZEtc"
      },
      "source": [
        "### C. Print count of each class from y. [2 Marks]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LfWsv7IvZJhp"
      },
      "source": [
        "# **2. Image Exploration & Transformation [Learning purpose - Not related to final model] [10 Marks]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxghivlXZNNs"
      },
      "source": [
        "### A. Display 5 random images. [1 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV1rcZDMZeMc"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hkQ7nVV_ZTPB"
      },
      "source": [
        "### B. Select any image from the dataset and assign it to a variable. [1 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Zt5P22L0ZdVq"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEOEyUaiZe2j"
      },
      "source": [
        "### C. Transform the image into grayscale format and display the same. [3 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd4bfFXyZnGL"
      },
      "outputs": [],
      "source": [
        "plt.imshow(image2[:,:,0],cmap='gray')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88BMlHLFaPjZ"
      },
      "source": [
        "### D. Apply a filter to sharpen the image and display the image before and after sharpening. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "o_6i16a8aRp8"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bRtIjfk6aScd"
      },
      "source": [
        "### E. Apply a filter to blur the image and display the image before and after blur. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1smz_9eNaVmv"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zw_Rqvooabha"
      },
      "source": [
        "### F. Display all the 4 images from above questions besides each other to observe the difference. [1 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ESUkTdnnafUn"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NML-pqf3aihV"
      },
      "source": [
        "# **3. Model training and Tuning: [15 Marks]**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TtiJ2DlzalLR"
      },
      "source": [
        "### A. Split the data into train and test with 80:20 proportion. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t9HSQuGPaqsi"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OyiMfOenaohK"
      },
      "source": [
        "### B. Train a model using any Supervised Learning algorithm and share performance metrics on test data. [3 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZgJNFDkSaydR"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gvhsoxDTaxQz"
      },
      "source": [
        "### C. Train a model using Neural Network and share performance metrics on test data. [4 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mEzn4IMKa2m4"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LFROeYfea5zB"
      },
      "source": [
        "### D. Train a model using a basic CNN and share performance metrics on test data. [4 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aAxwoi5ka9U5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AKmyHnAmbAmo"
      },
      "source": [
        "### E. Predict the class/label of image ‘Prediction.jpg’ using best performing model and share predicted label. [2 Marks]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "553-n-l4bE6h"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZAxEufo3bDoZ"
      },
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN08UD+n8uL5ZBNqbz1Tr/h",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}